{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "B62aj2RFYxNi",
        "outputId": "a41d0e45-918b-410f-fd36-c9fbdf1ded68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Epoch 1/1, Batch 0/782, Loss: 2.4357717037200928\n",
            "Epoch 1/1, Batch 100/782, Loss: 1.9979636669158936\n",
            "Epoch 1/1, Batch 200/782, Loss: 2.032679557800293\n",
            "Epoch 1/1, Batch 300/782, Loss: 1.7990580797195435\n",
            "Epoch 1/1, Batch 400/782, Loss: 1.906455397605896\n",
            "Epoch 1/1, Batch 500/782, Loss: 1.5445990562438965\n",
            "Epoch 1/1, Batch 600/782, Loss: 1.5406376123428345\n",
            "Epoch 1/1, Batch 700/782, Loss: 1.5161807537078857\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the basic building blocks: Residual Block\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = None\n",
        "\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "# Define the ResNet model\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self.make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self.make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self.make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "        # Add two fully connected layers for 1x512 outputs\n",
        "        self.fc1 = nn.Linear(512, 512)\n",
        "        self.fc2 = nn.Linear(512, 512)\n",
        "\n",
        "    def make_layer(self, block, out_channels, num_blocks, stride):\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride))\n",
        "        self.in_channels = out_channels\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(out_channels, out_channels, stride=1))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        \n",
        "        # Pass through two fully connected layers for 1x512 outputs\n",
        "        out1 = self.fc1(out)\n",
        "        out2 = self.fc2(out)\n",
        "        \n",
        "        # Concatenate the two 1x512 outputs to get a 1x1024 array\n",
        "        concatenated_output = torch.cat((out1, out2), dim=1)\n",
        "        \n",
        "        # Apply the final classification layer\n",
        "        output = self.fc(concatenated_output)\n",
        "        return output\n",
        "\n",
        "# Create a ResNet model\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2])\n",
        "\n",
        "# Instantiate the model\n",
        "model = ResNet18()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e6hxLA_aY45w",
        "outputId": "927edfd7-4a14-4147-b9e5-7edbe9f5e9f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Test Accuracy: 44.64%\n",
            "Average Test Loss: 1.5221\n"
          ]
        }
      ],
      "source": [
        "test_loader= model.forward(Image(filename='/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900))\n",
        "# Evaluation loop\n",
        "def evaluate(model, test_loader, criterion):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Calculate the number of correct predictions\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct_predictions += predicted.eq(targets).sum().item()\n",
        "\n",
        "            total_samples += targets.size(0)\n",
        "\n",
        "    # Calculate accuracy and average loss\n",
        "    accuracy = (correct_predictions / total_samples) * 100.0\n",
        "    average_loss = total_loss / len(test_loader)\n",
        "\n",
        "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Average Test Loss: {average_loss:.4f}\")\n",
        "\n",
        "# Call the evaluation function\n",
        "evaluate(model, test_loader, criterion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM26v9hyk37_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from IPython.display import Image, clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Flatten, Embedding, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Bidirectional(LSTM(512, activation=\"tanh\", return_sequences=True)),\n",
        "    Bidirectional(LSTM(256, activation=\"tanh\", return_sequences=True)),\n",
        "    Bidirectional(LSTM(128, activation=\"tanh\")),\n",
        "    Dropout(0.2),\n",
        "    Flatten(),\n",
        "    Dense(64, activation=\"relu\"),\n",
        "    Dropout(0.2),\n",
        "    Dense(32, activation=\"relu\"),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train= Image(filename='/content/yolov5/runs/train/yolov5s_results/train_batch0.jpg', width=900)\n",
        "# y_train is 0 if P2 wins and 1 if P1 wins\n",
        "hist = model.fit(x_train, 1, epochs=1000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
